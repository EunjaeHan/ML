{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHV6Be8KUJVX",
        "outputId": "2fc874b8-7e80-47fa-aeec-d7240151f9e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공통 전처리 셀"
      ],
      "metadata": {
        "id": "FpOmCqegaE3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# 1. 데이터 로드\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Alcohol_Sales.csv')\n",
        "data = df['S4248SM144NCEN'].values.reshape(-1, 1)\n",
        "\n",
        "# 2. 정규화\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# 3. 시퀀스 만들기 (12개월 → 다음달)\n",
        "window = 12\n",
        "X, y = [], []\n",
        "for i in range(len(data_scaled) - window):\n",
        "    X.append(data_scaled[i:i+window])\n",
        "    y.append(data_scaled[i+window])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# 4. train / test 분할\n",
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "input_shape = (window, 1)\n"
      ],
      "metadata": {
        "id": "7TPGdSKJZ6FX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 지난 주 실습 완성본"
      ],
      "metadata": {
        "id": "CS1CFJdjaI3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm():\n",
        "    model = models.Sequential([\n",
        "        layers.LSTM(64, input_shape=input_shape),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_cnn():\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(64, 3, padding='causal', activation='relu')(inp)\n",
        "    x = layers.Conv1D(64, 3, padding='causal', activation='relu')(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_cnn_lstm():\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(64, 3, padding='causal', activation='relu')(inp)\n",
        "    x = layers.Conv1D(64, 3, padding='causal', activation='relu')(x)\n",
        "    x = layers.LSTM(64)(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "models_to_run = {\n",
        "    \"LSTM\": build_lstm,\n",
        "    \"CNN\": build_cnn,\n",
        "    \"CNN+LSTM\": build_cnn_lstm,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, builder in models_to_run.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model = builder()\n",
        "    model.fit(X_train, y_train,\n",
        "              epochs=30,\n",
        "              batch_size=8,\n",
        "              validation_split=0.1,\n",
        "              verbose=0)\n",
        "    mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "    pred = model.predict(X_test)\n",
        "    true_vals = scaler.inverse_transform(y_test)\n",
        "    pred_vals = scaler.inverse_transform(pred)\n",
        "    mae = mean_absolute_error(true_vals, pred_vals)\n",
        "    results[name] = (mse, mae)\n",
        "    print(f\"{name} Test MSE: {mse:.6f} | MAE: {mae:.6f}\")\n",
        "\n",
        "print(\"\\n[요약]\")\n",
        "for k, v in results.items():\n",
        "    print(k, v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7RBTZkUaIlL",
        "outputId": "21b74e7c-67b6-4745-c591-04fae078fbe9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LSTM ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step\n",
            "LSTM Test MSE: 0.025324 | MAE: 1671.799805\n",
            "\n",
            "--- CNN ---\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "CNN Test MSE: 0.002250 | MAE: 480.322002\n",
            "\n",
            "--- CNN+LSTM ---\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
            "CNN+LSTM Test MSE: 0.007042 | MAE: 817.839766\n",
            "\n",
            "[요약]\n",
            "LSTM (0.02532353810966015, 1671.7998046875)\n",
            "CNN (0.0022495072335004807, 480.32200210813505)\n",
            "CNN+LSTM (0.007041792385280132, 817.8397662450398)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B안. 추가 실험 1 — CNN + SE 블록"
      ],
      "metadata": {
        "id": "ltdbgsBLaPmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def se_block(inputs, reduction=8):\n",
        "    ch = inputs.shape[-1]\n",
        "    x = layers.GlobalAveragePooling1D()(inputs)\n",
        "    x = layers.Dense(ch // reduction, activation='relu')(x)\n",
        "    x = layers.Dense(ch, activation='sigmoid')(x)\n",
        "    x = layers.Reshape((1, ch))(x)\n",
        "    return layers.Multiply()([inputs, x])\n",
        "\n",
        "inp = layers.Input(shape=input_shape)\n",
        "x = layers.Conv1D(64, 3, padding='causal', activation='relu')(inp)\n",
        "x = se_block(x)   # SE 추가\n",
        "x = layers.Conv1D(64, 3, padding='causal', activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "out = layers.Dense(1)(x)\n",
        "se_model = models.Model(inp, out)\n",
        "se_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = se_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "mse = se_model.evaluate(X_test, y_test, verbose=0)\n",
        "pred = se_model.predict(X_test)\n",
        "true_vals = scaler.inverse_transform(y_test)\n",
        "pred_vals = scaler.inverse_transform(pred)\n",
        "mae = mean_absolute_error(true_vals, pred_vals)\n",
        "\n",
        "print(f\"SE-CNN Test MSE: {mse:.6f} | MAE: {mae:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rffMrJVNaQti",
        "outputId": "e7af41ef-f441-4a35-8819-f3fe08414e04"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
            "SE-CNN Test MSE: 0.002672 | MAE: 545.476283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C안. 추가 실험 2 — Transformer Encoder 기반 시계열"
      ],
      "metadata": {
        "id": "iM1hfLplaUA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, num_heads=2, ff_dim=64, dropout=0.1):\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    attn = layers.MultiHeadAttention(num_heads=num_heads,\n",
        "                                     key_dim=inputs.shape[-1])(x, x)\n",
        "    attn = layers.Dropout(dropout)(attn)\n",
        "    x = layers.Add()([inputs, attn])\n",
        "\n",
        "    y = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    y = layers.Dense(ff_dim, activation='relu')(y)\n",
        "    y = layers.Dense(inputs.shape[-1])(y)\n",
        "    y = layers.Dropout(dropout)(y)\n",
        "    return layers.Add()([x, y])\n",
        "\n",
        "inp = layers.Input(shape=input_shape)\n",
        "x = transformer_encoder(inp, num_heads=2, ff_dim=64, dropout=0.1)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "out = layers.Dense(1)(x)\n",
        "trans_model = models.Model(inp, out)\n",
        "trans_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "trans_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "mse = trans_model.evaluate(X_test, y_test, verbose=0)\n",
        "pred = trans_model.predict(X_test)\n",
        "true_vals = scaler.inverse_transform(y_test)\n",
        "pred_vals = scaler.inverse_transform(pred)\n",
        "mae = mean_absolute_error(true_vals, pred_vals)\n",
        "\n",
        "print(f\"Transformer Encoder Test MSE: {mse:.6f} | MAE: {mae:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBBZkQtFaUkG",
        "outputId": "b4abaaf4-174a-4ee9-c37b-ed97115de7f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "Transformer Encoder Test MSE: 0.014161 | MAE: 1204.548270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D안. 추가 실험 3 — CNN + CBAM"
      ],
      "metadata": {
        "id": "jrmI9g3iaW3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "# CBAM 1D\n",
        "def cbam_block(inputs, reduction=8):\n",
        "    ch = inputs.shape[-1]\n",
        "\n",
        "    # ----- 1) Channel Attention -----\n",
        "    avg_pool = layers.GlobalAveragePooling1D()(inputs)   # (batch, ch)\n",
        "    max_pool = layers.GlobalMaxPooling1D()(inputs)       # (batch, ch)\n",
        "\n",
        "    shared_dense = layers.Dense(ch // reduction, activation='relu')\n",
        "    mlp_avg = shared_dense(avg_pool)\n",
        "    mlp_max = shared_dense(max_pool)\n",
        "\n",
        "    mlp_avg = layers.Dense(ch)(mlp_avg)\n",
        "    mlp_max = layers.Dense(ch)(mlp_max)\n",
        "\n",
        "    channel_attn = layers.Add()([mlp_avg, mlp_max])\n",
        "    channel_attn = layers.Activation('sigmoid')(channel_attn)\n",
        "    channel_attn = layers.Reshape((1, ch))(channel_attn)  # (batch, 1, ch)\n",
        "\n",
        "    x = layers.Multiply()([inputs, channel_attn])  # (batch, time, ch)\n",
        "\n",
        "    # ----- 2) Spatial Attention -----\n",
        "    # 평균과 최대를 time축으로 모아서 concat -> conv1d\n",
        "    avg_pool_spatial = layers.Lambda(lambda t: tf.reduce_mean(t, axis=-1, keepdims=True))(x)\n",
        "    max_pool_spatial = layers.Lambda(lambda t: tf.reduce_max(t, axis=-1, keepdims=True))(x)\n",
        "    spatial = layers.Concatenate(axis=-1)([avg_pool_spatial, max_pool_spatial])  # (batch, time, 2)\n",
        "    spatial = layers.Conv1D(filters=1, kernel_size=3, padding='same', activation='sigmoid')(spatial)\n",
        "    out = layers.Multiply()([x, spatial])\n",
        "    return out\n",
        "\n",
        "# ====== 모델 본체 ======\n",
        "inp = layers.Input(shape=input_shape)\n",
        "x = layers.Conv1D(64, 3, padding='causal', activation='relu')(inp)\n",
        "x = cbam_block(x)          # 여기 이제 에러 안 남\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "out = layers.Dense(1)(x)\n",
        "cbam_model = models.Model(inp, out)\n",
        "cbam_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "cbam_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "mse = cbam_model.evaluate(X_test, y_test, verbose=0)\n",
        "pred = cbam_model.predict(X_test)\n",
        "true_vals = scaler.inverse_transform(y_test)\n",
        "pred_vals = scaler.inverse_transform(pred)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(true_vals, pred_vals)\n",
        "\n",
        "print(f\"CBAM-CNN Test MSE: {mse:.6f} | MAE: {mae:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj-I0RA2a0bR",
        "outputId": "6562250b-3ddd-453d-e977-c93bedd2ec63"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "CBAM-CNN Test MSE: 0.014771 | MAE: 1163.668697\n"
          ]
        }
      ]
    }
  ]
}